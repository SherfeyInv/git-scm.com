name: 'Run Hugo/Pagefind and deploy to GitHub Pages'
description: 'Runs Hugo and Pagefind and then deploys the result to GitHub Pages.'
# This composite Action requires the following things in the calling workflow:
#
# permissions:
#   contents: write # to push changes (if any)
#   pages: write # to deploy to GitHub Pages
#   id-token: write # to verify that the deployment source is legit
# environment:
#   name: github-pages
#   url: ${{ steps.<id-of-deployment-step>.outputs.url }}
inputs:
  github-token:
    description: The GitHub token used to create an authenticated client
    default: ${{ github.token }}
    required: true
  cloudflare-token:
    description: The Cloudflare API token used to purge Cloudflare caches.
    required: false
  cloudflare-zone:
    description: The Cloudflare zone to purge.
    required: false
  external-https:
    description: Whether HTTPS is set up externally, e.g. on Cloudflare instead of GitHub.
    default: false
    required: false
outputs:
  url:
    description: The URL to which the site was deployed
    value: ${{ steps.deploy.outputs.page_url }}
runs:
  using: "composite"
  steps:
    - name: push changes (if needed)
      shell: bash
      run: |
        test "$(git rev-parse HEAD)" = "$(git rev-parse refs/remotes/origin/${{ github.ref_name }})" ||
        git push origin HEAD:${{ github.ref }}

    - name: un-sparse worktree to prepare for deployment
      shell: bash
      run: git sparse-checkout disable

    - name: setup GitHub Pages
      id: pages
      uses: actions/configure-pages@v5

    - name: set base URL
      shell: bash
      run: |
        base_url="${{ steps.pages.outputs.base_url }}"
        if [ "${{ inputs.external-https }}" = true ] ; then
          base_url="$(echo "$base_url" | sed 's/^http:/https:/')"
        fi
        echo "base_url=$base_url" >>"$GITHUB_ENV"

    - name: configure Hugo and Pagefind version
      shell: bash
      run: |
        set -x &&
        echo "HUGO_VERSION=$(sed -n 's/^ *hugo_version: *//p' <hugo.yml)" >>$GITHUB_ENV
        echo "PAGEFIND_VERSION=$(sed -n 's/^ *pagefind_version: *//p' <hugo.yml)" >>$GITHUB_ENV

    - name: install Hugo ${{ env.HUGO_VERSION }}
      shell: bash
      run: |
        set -x &&
        curl -Lo /tmp/hugo.deb https://github.com/gohugoio/hugo/releases/download/v$HUGO_VERSION/hugo_extended_${HUGO_VERSION}_linux-amd64.deb &&
        sudo dpkg -i /tmp/hugo.deb

    - name: run Hugo to build the pages
      env:
        HUGO_RELATIVEURLS: false
      shell: bash
      run: hugo config && hugo --baseURL "${{ env.base_url }}/"

    - name: run Pagefind ${{ env.PAGEFIND_VERSION }} to build the search index
      shell: bash
      run: npx -y pagefind@${{ env.PAGEFIND_VERSION }} --site public

    - name: Temporarily copy some Rails assets to help the transition
      shell: bash
      run: |
        # To help with the transition from the Rails app to the Hugo/Pagefind site, where
        # at least for a while the cached version of git-scm.com might be served via
        # Cloudflare, according to the first transition attempt on Sep 20, 2024, potentially
        # partially, i.e. _some_ assets might still be cached, _some_ others might not, let's
        # copy the most prominent assets to the new page so that, say, the original front page
        # won't fail to load the style sheet and Javascript libraries that it needs.
        set -x &&
        mkdir -p public/assets &&
        for f in application-93865c5c820c24f4c599e8b9c544bcd8a0d03260f9b16c9ba80b6a00082112c9.css \
          application-f7a750114a26afea236a5cc26f6ff3925a14c5901e9ea9018fb869432d0cbee3.js \
          modernize-b3ebe0c31c24f230dc62179d3e1030d2e57a53b1668d9382c0a27dbd44a94beb.js
        do
          curl -Lfo public/assets/$f https://git-scm.com/assets/$f ||
          echo "::error::could not copy $f from https://git-scm.com/" >&2
        done

    - name: upload GitHub Pages artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: ./public

    - name: deploy
      id: deploy
      uses: actions/deploy-pages@v4

    - name: Purge Cloudflare cache
      id: cloudflare
      shell: bash
      env:
        CLOUDFLARE_ZONE: ${{ inputs.cloudflare-zone }}
        CLOUDFLARE_TOKEN: ${{ inputs.cloudflare-token }}
      if: env.CLOUDFLARE_TOKEN != ''
      run: |
        curl "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE/purge_cache" \
          -H "Authorization: Bearer $CLOUDFLARE_TOKEN" \
          -H "Content-Type: application/json" \
          -d '{ "purge_everything": true }'

    - name: construct `--remap` options for lychee
      id: remap
      shell: bash
      run: |
        echo "result=$(echo "$base_url" |
          sed 's|^\(.*\)\(/git-scm\.com\)$|(\1)?\2(.*)|') file://$PWD/public\$2" \
          >>$GITHUB_OUTPUT
        # When running in forks, do detect when links try to break out of the
        # `/git-scm.com/` subdirectory
        echo "remap-dotdot=$(echo "$base_url" |
          sed -n 's|^\(https\?:\/\/.*\)\(/git-scm\.com\)$|--remap '\''(\1.*) file://../$1'\''|p')" \
          >>$GITHUB_OUTPUT

    - name: check for downgrades to unencrypted HTTP
      if: startsWith(env.base_url, 'https://')
      shell: bash
      # The `--require-https` option of lychee could come in handy,
      # but it also complains about `http://` links to other sites,
      # and (more importantly) doesn't work in offline mode.
      # A simple `grep` should work without any false positives,
      # unless git-scm.com mentions the base URL of one of its forks,
      # which is unlikely.
      run: '! grep -FInr "http:${base_url#https:}" public'

    - name: check for broken links
      id: lychee
      uses: lycheeverse/lychee-action@v2
      with:
        args: >-
          --offline
          --fallback-extensions html
          --base '${{ env.base_url }}'
          --remap '${{ steps.remap.outputs.result }}'
          ${{ steps.remap.outputs.remap-dotdot }}
          --exclude file:///path/to/repo.git/
          --exclude file:///caminho/para/o/reposit%C3%B3rio.git/
          --exclude file:///ruta/a/repositorio.git/
          --exclude file:///sl%C3%B3%C3%B0/til/hirsla.git/
          --exclude file:///Pfad/zum/Repo.git/
          --exclude file:///chemin/du/d%C3%A9p%C3%B4t.git/
          --exclude file:///srv/git/project.git
          public/
        output: lychee.md
        jobSummary: true
        fail: false
        failIfEmpty: false # needed because its default overrides `fail = false`

    - name: ${{ env.lychee_exit_code != '0' && 'open or update' || 'maybe close' }} link checker issue
      if: env.lychee_exit_code != ''
      uses: actions/github-script@v7
      with:
        github-token: ${{ inputs.github-token }}
        script: |
          const fs = await import('fs')
          // GitHub issues can only have 64k characters in their body
          const body = (s => {
            if (s.length < 65535) return s
            return s.replace(/^([^]{0,65000}\n)[^]*\n(.+)\n?$/, '$1\n[...]\n\n$2')
          })(await fs.promises.readFile('lychee.md', 'utf8'))

          const req = { owner: context.repo.owner, repo: context.repo.repo }
          const issues = await (async () => {
            const q = `"Link+Checker+Report"+in:title+is:issue+label:linkchecker+is:open+repo:${req.owner}/${req.repo}`
            try {
              return await github.rest.search.issuesAndPullRequests({ ...req, q, sort: 'created', per_page: 1 })
            } catch (e) {
              console.log(`Warning: ${e}; sleeping for 30 seconds and falling back to calling listForRepo()`)
              await new Promise(r => setTimeout(r, 30000))

              const issues = await github.rest.issues.listForRepo({...req, state: 'open', per_page: 100})
              return {
                data: {
                  items: issues.data.filter(
                    e => e.title === 'Link Checker Report'
                    && e.labels.filter(l => l.name === 'linkchecker').length > 0
                  )
                }
              }
            }
          })()

          if (issues.data.items.length === 0) {
            if (process.env.lychee_exit_code !== '0') {
              await github.rest.issues.create({ ...req, title: 'Link Checker Report', body, labels: ['linkchecker'] })
            }
          } else {
            req.issue_number = issues.data.items[0].number
            await github.rest.issues.createComment({ ...req, body })
            if (process.env.lychee_exit_code === '0') {
              await github.rest.issues.update({ ...req, state: 'closed' })
            }
          }

    - name: Install @playwright/test
      shell: bash
      run: npm install @playwright/test
    - name: Edit /etc/hosts to map the deployed domain to GitHub
      shell: bash
      # This side-steps any caches that might be configured on the domain,
      # and works even when the real server is not reachable from GitHub.
      run: |
        host="$(echo "$base_url" | sed -E 's|^https?://([^:/]+).*|\1|')"
        sudo sh -c "echo '185.199.108.153 $host' >>/etc/hosts"
    - name: Run Playwright tests
      shell: bash
      id: playwright
      env:
        PLAYWRIGHT_TEST_URL: ${{ env.base_url }}
        # avoid test failures when HTTPS is enforced half-way through
        PLAYWRIGHT_EXTERNAL_HTTPS: ${{ inputs.external-https }}
      run: npx playwright test --project=chrome
    - uses: actions/upload-artifact@v4
      if: always() && steps.playwright.outputs.result != ''
      with:
        name: playwright-report
        path: playwright-report/